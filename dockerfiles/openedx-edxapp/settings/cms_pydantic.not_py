"""
Settings file that uses pydantic-settings to load configuration.
This is the new production settings file.
"""

# We intentionally define lots of variables that aren't used, and
# want to import all variables from base settings files
# pylint: disable=wildcard-import, unused-wildcard-import, useless-suppression, wrong-import-order, wrong-import-position

import codecs
import os
import warnings
import yaml
from typing import Optional, List, Dict, Any, Tuple

from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic_settings.sources import (
    YamlConfigSettingsSource,
    PydanticBaseSettingsSource,
)
from django.core.exceptions import ImproperlyConfigured
from django.urls import reverse_lazy
from edx_django_utils.plugins import add_plugins
from openedx_events.event_bus import merge_producer_configs
from path import Path as path

# Import all common settings
from .common import *

from openedx.core.djangoapps.plugins.constants import ProjectType, SettingsType
from openedx.core.lib.derived import derive_settings
from openedx.core.lib.logsettings import get_logger_config
from xmodule.modulestore.modulestore_settings import (
    convert_module_store_setting_if_needed,
)


class PydanticAppSettings(BaseSettings):
    """
    Define settings to be loaded from the environment here.

    These settings will be loaded from environment variables or from YAML
    configuration files. To specify YAML files, set the
    `CMS_SETTINGS_YAML_FILES` environment variable to a comma-separated
    list of file paths.
    """

    model_config = SettingsConfigDict(
        case_sensitive=False,
        extra="allow",
    )

    # Settings from production.py defaults and YAML
    DEBUG: bool = False
    AUTHORING_API_URL: str = ""
    AWS_QUERYSTRING_AUTH: bool = True
    AWS_S3_CUSTOM_DOMAIN: str = "edxuploads.s3.amazonaws.com"
    AWS_STORAGE_BUCKET_NAME: str = "edxuploads"
    BROKER_HEARTBEAT: float = 60.0
    BROKER_HEARTBEAT_CHECKRATE: int = 2
    CELERY_ALWAYS_EAGER: bool = False
    CELERY_BROKER_HOSTNAME: str = ""
    CELERY_BROKER_PASSWORD: str = ""
    CELERY_BROKER_TRANSPORT: str = ""
    CELERY_BROKER_USER: str = ""
    CELERY_RESULT_BACKEND: str = "django-cache"
    CHAT_COMPLETION_API: str = ""
    CHAT_COMPLETION_API_KEY: str = ""
    CLEAR_REQUEST_CACHE_ON_TASK_COMPLETION: bool = True
    CMS_BASE: Optional[str] = None
    CMS_ROOT_URL: Optional[str] = None
    IDA_LOGOUT_URI_LIST: List[str] = []
    LEARNER_ENGAGEMENT_PROMPT_FOR_ACTIVE_CONTRACT: str = ""
    LEARNER_ENGAGEMENT_PROMPT_FOR_NON_ACTIVE_CONTRACT: str = ""
    LEARNER_PROGRESS_PROMPT_FOR_ACTIVE_CONTRACT: str = ""
    LEARNER_PROGRESS_PROMPT_FOR_NON_ACTIVE_CONTRACT: str = ""
    LMS_BASE: Optional[str] = None
    LMS_ROOT_URL: Optional[str] = None
    OPENAPI_CACHE_TIMEOUT: int = 60 * 60
    PARSE_KEYS: Dict[str, Any] = {}
    REGISTRATION_EMAIL_PATTERNS_ALLOWED: Optional[List[str]] = None
    SESSION_COOKIE_DOMAIN: Optional[str] = None
    SESSION_COOKIE_HTTPONLY: bool = True
    SESSION_ENGINE: str = "django.contrib.sessions.backends.cache"
    SESSION_INACTIVITY_TIMEOUT_IN_SECONDS: Optional[int] = None
    STATIC_ROOT_BASE: Optional[str] = None
    STATIC_URL_BASE: Optional[str] = None
    VIDEO_CDN_URL: Dict[str, Any] = {}

    # Special dicts that are merged
    FEATURES: Dict[str, Any] = {}
    TRACKING_BACKENDS: Dict[str, Any] = {}
    EVENT_TRACKING_BACKENDS: Dict[str, Any] = {}
    JWT_AUTH: Dict[str, Any] = {}
    CELERY_QUEUES: Optional[List[str]] = None
    MKTG_URL_LINK_MAP: Dict[str, Any] = {}
    REST_FRAMEWORK: Dict[str, Any] = {}
    EVENT_BUS_PRODUCER_CONFIG: Dict[str, Any] = {}

    # Other settings from YAML/env
    REVISION_CFG: Optional[str] = None
    ADDL_INSTALLED_APPS: List[str] = []
    SEGMENT_KEY: Optional[str] = None
    AWS_ACCESS_KEY_ID: Optional[str] = None
    AWS_SECRET_ACCESS_KEY: Optional[str] = None
    DEFAULT_FILE_STORAGE: Optional[str] = None
    COURSE_IMPORT_EXPORT_BUCKET: str = ""
    COURSE_METADATA_EXPORT_BUCKET: str = ""
    CELERY_BROKER_TRANSPORT_OPTIONS: Dict[str, Any] = {}
    ALTERNATE_WORKER_QUEUES: str = ""
    ELASTIC_SEARCH_CONFIG_ES7: List[Dict[str, Any]] = [{}]
    YOUTUBE_API_KEY: str = "PUT_YOUR_API_KEY_HERE"
    LANGUAGE_COOKIE: Optional[str] = None
    BIG_BLUE_BUTTON_GLOBAL_KEY: Optional[str] = None
    BIG_BLUE_BUTTON_GLOBAL_SECRET: Optional[str] = None
    BIG_BLUE_BUTTON_GLOBAL_URL: Optional[str] = None

    # Env vars from production.py
    STATICFILES_STORAGE: Optional[str] = None
    DB_MIGRATION_ENGINE: Optional[str] = None
    DB_MIGRATION_USER: Optional[str] = None
    DB_MIGRATION_PASS: Optional[str] = None
    DB_MIGRATION_NAME: Optional[str] = None
    DB_MIGRATION_HOST: Optional[str] = None
    DB_MIGRATION_PORT: Optional[str] = None

    @classmethod
    def settings_customise_sources(
        cls,
        settings_cls: type[BaseSettings],
        init_settings: PydanticBaseSettingsSource,
        env_settings: PydanticBaseSettingsSource,
        dotenv_settings: PydanticBaseSettingsSource,
        file_secret_settings: PydanticBaseSettingsSource,
    ) -> tuple[PydanticBaseSettingsSource, ...]:
        """
        Customize settings sources to include YAML files and remove .env support.

        You can provide a comma-separated list of YAML file paths
        via the CMS_SETTINGS_YAML_FILES environment variable.
        e.g., CMS_SETTINGS_YAML_FILES="/path/to/config1.yaml,/path/to/config2.yaml"
        Files listed later in the string have higher priority over earlier ones.

        The priority of settings sources is (from highest to lowest):
        1. Arguments passed to the constructor (`init_settings`).
        2. Environment variables (`env_settings`).
        3. YAML files (from `CMS_SETTINGS_YAML_FILES`).
        4. Secret files (`file_secret_settings`).
        """
        yaml_sources = []
        yaml_files_str = os.environ.get("CMS_SETTINGS_YAML_FILES")
        if yaml_files_str:
            # Files listed later in the string should have higher priority,
            # so we process them in order and they will be placed in the
            # sources tuple in increasing order of priority.
            yaml_files = [path.strip() for path in yaml_files_str.split(",")]
            for yaml_file in yaml_files:
                if os.path.exists(yaml_file):
                    yaml_sources.append(
                        YamlConfigSettingsSource(settings_cls, yaml_file=yaml_file)
                    )

        return (
            file_secret_settings,
            *yaml_sources,
            env_settings,
            init_settings,
        )


# Load settings from environment
pydantic_settings = PydanticAppSettings()
_pydantic_settings_dict = pydantic_settings.model_dump(exclude_unset=True)

#######################################################################################################################
#### PRODUCTION DEFAULTS
####
#### Configure some defaults (beyond what has already been configured in common.py).
#### DO NOT ADD NEW DEFAULTS HERE! Put any new setting defaults in common.py instead, along with a setting annotation.
#### TODO: Move all these defaults into common.py.
####

DEBUG = False

# IMPORTANT: With this enabled, the server must always be behind a proxy that strips the header HTTP_X_FORWARDED_PROTO
# from client requests. Otherwise, a user can fool our server into thinking it was an https connection. See
# https://docs.djangoproject.com/en/dev/ref/settings/#secure-proxy-ssl-header for other warnings.
SECURE_PROXY_SSL_HEADER = ("HTTP_X_FORWARDED_PROTO", "https")

# Constant defaults (alphabetical)
AUTHORING_API_URL = ""
AWS_QUERYSTRING_AUTH = True
AWS_S3_CUSTOM_DOMAIN = "edxuploads.s3.amazonaws.com"
AWS_STORAGE_BUCKET_NAME = "edxuploads"
BROKER_HEARTBEAT = 60.0
BROKER_HEARTBEAT_CHECKRATE = 2
CELERY_ALWAYS_EAGER = False
CELERY_BROKER_HOSTNAME = ""
CELERY_BROKER_PASSWORD = ""
CELERY_BROKER_TRANSPORT = ""
CELERY_BROKER_USER = ""
CELERY_RESULT_BACKEND = "django-cache"
CHAT_COMPLETION_API = ""
CHAT_COMPLETION_API_KEY = ""
CLEAR_REQUEST_CACHE_ON_TASK_COMPLETION = True
CMS_BASE = None
CMS_ROOT_URL = None
DEFAULT_TEMPLATE_ENGINE["OPTIONS"]["debug"] = False
IDA_LOGOUT_URI_LIST = []
LEARNER_ENGAGEMENT_PROMPT_FOR_ACTIVE_CONTRACT = ""
LEARNER_ENGAGEMENT_PROMPT_FOR_NON_ACTIVE_CONTRACT = ""
LEARNER_PROGRESS_PROMPT_FOR_ACTIVE_CONTRACT = ""
LEARNER_PROGRESS_PROMPT_FOR_NON_ACTIVE_CONTRACT = ""
LMS_BASE = None
LMS_ROOT_URL = None
OPENAPI_CACHE_TIMEOUT = 60 * 60
PARSE_KEYS = {}
REGISTRATION_EMAIL_PATTERNS_ALLOWED = None
SESSION_COOKIE_DOMAIN = None
SESSION_COOKIE_HTTPONLY = True
SESSION_ENGINE = "django.contrib.sessions.backends.cache"
SESSION_INACTIVITY_TIMEOUT_IN_SECONDS = None
STATIC_ROOT_BASE = None
STATIC_URL_BASE = None
VIDEO_CDN_URL = {}

# Derived defaults (alphabetical)
BROKER_USE_SSL = Derived(lambda settings: settings.CELERY_BROKER_USE_SSL)
EMAIL_FILE_PATH = Derived(lambda settings: settings.DATA_DIR / "emails" / "studio")
ENTERPRISE_API_URL = Derived(
    lambda settings: settings.LMS_INTERNAL_ROOT_URL + "/enterprise/api/v1/"
)
ENTERPRISE_CONSENT_API_URL = Derived(
    lambda settings: settings.LMS_INTERNAL_ROOT_URL + "/consent/api/v1/"
)
LMS_INTERNAL_ROOT_URL = Derived(lambda settings: settings.LMS_ROOT_URL)
POLICY_CHANGE_GRADES_ROUTING_KEY = Derived(
    lambda settings: settings.DEFAULT_PRIORITY_QUEUE
)
SCRAPE_YOUTUBE_THUMBNAILS_JOB_QUEUE = Derived(
    lambda settings: settings.DEFAULT_PRIORITY_QUEUE
)
SHARED_COOKIE_DOMAIN = Derived(lambda settings: settings.SESSION_COOKIE_DOMAIN)
SINGLE_LEARNER_COURSE_REGRADE_ROUTING_KEY = Derived(
    lambda settings: settings.DEFAULT_PRIORITY_QUEUE
)
SOFTWARE_SECURE_VERIFICATION_ROUTING_KEY = Derived(
    lambda settings: settings.HIGH_PRIORITY_QUEUE
)
UPDATE_SEARCH_INDEX_JOB_QUEUE = Derived(
    lambda settings: settings.DEFAULT_PRIORITY_QUEUE
)
VIDEO_TRANSCRIPT_MIGRATIONS_JOB_QUEUE = Derived(
    lambda settings: settings.DEFAULT_PRIORITY_QUEUE
)

#######################################################################################################################
#### Pydantic Settings Loading
####

# Update the global namespace of this module with the key-value pairs from pydantic_settings.
# In other words: For (almost) every pydantic setting, define/update a Django setting with that name and value.
special_keys_to_merge = [
    "FEATURES",
    "TRACKING_BACKENDS",
    "EVENT_TRACKING_BACKENDS",
    "JWT_AUTH",
    "MKTG_URL_LINK_MAP",
    "REST_FRAMEWORK",
    "EVENT_BUS_PRODUCER_CONFIG",
]

for key, value in _pydantic_settings_dict.items():
    # CELERY_QUEUES is handled separately below.
    if key.upper() not in special_keys_to_merge and key.upper() != "CELERY_QUEUES":
        globals()[key.upper()] = value

#######################################################################################################################
#### LOAD THE EDX-PLATFORM GIT REVISION
####

try:
    # A file path to a YAML file from which to load all the code revisions currently deployed
    REVISION_CONFIG_FILE = pydantic_settings.REVISION_CFG

    with codecs.open(REVISION_CONFIG_FILE, encoding="utf-8") as f:
        REVISION_CONFIG = yaml.safe_load(f)
except (TypeError, FileNotFoundError, yaml.YAMLError):
    REVISION_CONFIG = {}

# Do NOT calculate this dynamically at startup with git because it's *slow*.
EDX_PLATFORM_REVISION = REVISION_CONFIG.get(
    "EDX_PLATFORM_REVISION", EDX_PLATFORM_REVISION
)


#######################################################################################################################
#### POST-PROCESSING OF SETTINGS
####
#### This is where we do a bunch of logic to post-process the results of the settings, including: conditionally setting
#### updates, merging dicts+lists which we did not override, and in some cases simply ignoring the pydantic value in favor
#### of a specific production value.
####

# Don't use a connection pool, since connections are dropped by ELB.
BROKER_POOL_LIMIT = 0
BROKER_CONNECTION_TIMEOUT = 1

# Each worker should only fetch one message at a time
CELERYD_PREFETCH_MULTIPLIER = 1

CELERY_ROUTES = "openedx.core.lib.celery.routers.route_task"

if STATIC_URL_BASE:
    STATIC_URL = STATIC_URL_BASE
    if not STATIC_URL.endswith("/"):
        STATIC_URL += "/"
    STATIC_URL += "studio/"

if STATIC_ROOT_BASE:
    STATIC_ROOT = path(STATIC_ROOT_BASE) / "studio"
    WEBPACK_LOADER["DEFAULT"]["STATS_FILE"] = STATIC_ROOT / "webpack-stats.json"
    WEBPACK_LOADER["WORKERS"]["STATS_FILE"] = STATIC_ROOT / "webpack-worker-stats.json"

DATA_DIR = path(DATA_DIR)

ALLOWED_HOSTS = [
    # TODO: bbeggs remove this before prod, temp fix to get load testing running
    "*",
    CMS_BASE,
]

# Cache used for location mapping -- called many times with the same key/value
# in a given request.
if "loc_cache" not in CACHES:
    CACHES["loc_cache"] = {
        "BACKEND": "django.core.cache.backends.locmem.LocMemCache",
        "LOCATION": "edx_location_mem_cache",
    }

if "staticfiles" in CACHES:
    CACHES["staticfiles"]["KEY_PREFIX"] = EDX_PLATFORM_REVISION

# In order to transition from local disk asset storage to S3 backed asset storage,
# we need to run asset collection twice, once for local disk and once for S3.
# Once we have migrated to service assets off S3, then we can convert this back to
# managed by the yaml file contents
if hasattr(pydantic_settings, "STATICFILES_STORAGE"):
    STATICFILES_STORAGE = pydantic_settings.STATICFILES_STORAGE
if hasattr(pydantic_settings, "CSRF_TRUSTED_ORIGINS"):
    CSRF_TRUSTED_ORIGINS = pydantic_settings.CSRF_TRUSTED_ORIGINS

MKTG_URL_LINK_MAP.update(pydantic_settings.MKTG_URL_LINK_MAP)

# Timezone overrides
TIME_ZONE = CELERY_TIMEZONE

FEATURES.update(pydantic_settings.FEATURES)

# Additional installed apps
for app in pydantic_settings.ADDL_INSTALLED_APPS:
    INSTALLED_APPS.append(app)

LOGGING = get_logger_config(
    LOG_DIR,
    logging_env=LOGGING_ENV,
    service_variant=SERVICE_VARIANT,
)

LOGIN_REDIRECT_WHITELIST.extend([reverse_lazy("home")])

############### XBlock filesystem field config ##########
if "url_root" in DJFS:
    DJFS["url_root"] = DJFS["url_root"].format(platform_revision=EDX_PLATFORM_REVISION)

# Note that this is the Studio key for Segment. There is a separate key for the LMS.
CMS_SEGMENT_KEY = pydantic_settings.SEGMENT_KEY

if AWS_ACCESS_KEY_ID == "":
    AWS_ACCESS_KEY_ID = None

if AWS_SECRET_ACCESS_KEY == "":
    AWS_SECRET_ACCESS_KEY = None

AWS_DEFAULT_ACL = "private"
AWS_BUCKET_ACL = AWS_DEFAULT_ACL
# The number of seconds that a generated URL is valid for.
AWS_QUERYSTRING_EXPIRE = 7 * 24 * 60 * 60  # 7 days

# Change to S3Boto3 if we haven't specified another default storage AND we have specified AWS creds.
if (
    (not pydantic_settings.DEFAULT_FILE_STORAGE)
    and AWS_ACCESS_KEY_ID
    and AWS_SECRET_ACCESS_KEY
):
    DEFAULT_FILE_STORAGE = "storages.backends.s3boto3.S3Boto3Storage"

if COURSE_IMPORT_EXPORT_BUCKET:
    COURSE_IMPORT_EXPORT_STORAGE = (
        "cms.djangoapps.contentstore.storage.ImportExportS3Storage"
    )
else:
    COURSE_IMPORT_EXPORT_STORAGE = DEFAULT_FILE_STORAGE

USER_TASKS_ARTIFACT_STORAGE = COURSE_IMPORT_EXPORT_STORAGE

if COURSE_METADATA_EXPORT_BUCKET:
    COURSE_METADATA_EXPORT_STORAGE = (
        "cms.djangoapps.export_course_metadata.storage.CourseMetadataExportS3Storage"
    )
else:
    COURSE_METADATA_EXPORT_STORAGE = DEFAULT_FILE_STORAGE

# The normal database user does not have enough permissions to run migrations.
# Migrations are run with separate credentials, given as DB_MIGRATION_*
# environment variables
for name, database in DATABASES.items():
    if name != "read_replica":
        database.update(
            {
                "ENGINE": pydantic_settings.DB_MIGRATION_ENGINE or database["ENGINE"],
                "USER": pydantic_settings.DB_MIGRATION_USER or database["USER"],
                "PASSWORD": pydantic_settings.DB_MIGRATION_PASS or database["PASSWORD"],
                "NAME": pydantic_settings.DB_MIGRATION_NAME or database["NAME"],
                "HOST": pydantic_settings.DB_MIGRATION_HOST or database["HOST"],
                "PORT": pydantic_settings.DB_MIGRATION_PORT or database["PORT"],
            }
        )

MODULESTORE = convert_module_store_setting_if_needed(MODULESTORE)

# Celery Broker

BROKER_URL = "{}://{}:{}@{}/{}".format(
    CELERY_BROKER_TRANSPORT,
    CELERY_BROKER_USER,
    CELERY_BROKER_PASSWORD,
    CELERY_BROKER_HOSTNAME,
    CELERY_BROKER_VHOST,
)

try:
    BROKER_TRANSPORT_OPTIONS = {
        "fanout_patterns": True,
        "fanout_prefix": True,
        **pydantic_settings.CELERY_BROKER_TRANSPORT_OPTIONS,
    }
except TypeError as exc:
    raise ImproperlyConfigured(
        "CELERY_BROKER_TRANSPORT_OPTIONS must be a dict"
    ) from exc

# Build a CELERY_QUEUES dict the way that celery expects, based on a couple lists of queue names from the settings.
_pydantic_celery_queues = pydantic_settings.CELERY_QUEUES
if _pydantic_celery_queues:
    CELERY_QUEUES = {queue: {} for queue in _pydantic_celery_queues}

# Then add alternate environment queues
_pydantic_alternate_worker_queues = pydantic_settings.ALTERNATE_WORKER_QUEUES.split()
ALTERNATE_QUEUES = [
    DEFAULT_PRIORITY_QUEUE.replace(QUEUE_VARIANT, alternate + ".")
    for alternate in _pydantic_alternate_worker_queues
]

CELERY_QUEUES.update(
    {
        alternate: {}
        for alternate in ALTERNATE_QUEUES
        if alternate not in list(CELERY_QUEUES.keys())
    }
)

# Event tracking
TRACKING_BACKENDS.update(pydantic_settings.TRACKING_BACKENDS)
EVENT_TRACKING_BACKENDS["tracking_logs"]["OPTIONS"]["backends"].update(
    pydantic_settings.EVENT_TRACKING_BACKENDS
)
EVENT_TRACKING_BACKENDS["segmentio"]["OPTIONS"]["processors"][0]["OPTIONS"][
    "whitelist"
].extend(EVENT_TRACKING_SEGMENTIO_EMIT_WHITELIST)


if FEATURES["ENABLE_COURSEWARE_INDEX"] or FEATURES["ENABLE_LIBRARY_INDEX"]:
    # Use ElasticSearch for the search engine
    SEARCH_ENGINE = "search.elastic.ElasticSearchEngine"

# TODO: Once we have successfully upgraded to ES7, switch this back to ELASTIC_SEARCH_CONFIG.
ELASTIC_SEARCH_CONFIG = pydantic_settings.ELASTIC_SEARCH_CONFIG_ES7

XBLOCK_SETTINGS.setdefault("VideoBlock", {})["licensing_enabled"] = FEATURES[
    "LICENSING"
]
XBLOCK_SETTINGS.setdefault("VideoBlock", {})["YOUTUBE_API_KEY"] = YOUTUBE_API_KEY

############################ OAUTH2 Provider ###################################

#### JWT configuration ####
JWT_AUTH.update(pydantic_settings.JWT_AUTH)

######################## CUSTOM COURSES for EDX CONNECTOR ######################
if FEATURES["CUSTOM_COURSES_EDX"]:
    INSTALLED_APPS.append("openedx.core.djangoapps.ccxcon.apps.CCXConnectorConfig")

########################## Extra middleware classes  #######################

# Allow extra middleware classes to be added to the app through configuration.
MIDDLEWARE.extend(EXTRA_MIDDLEWARE_CLASSES)


#######################################################################################################################
#### DERIVE ANY DERIVED SETTINGS
####

derive_settings(__name__)


#######################################################################################################################
#### LOAD SETTINGS FROM DJANGO PLUGINS
####
#### This is at the bottom because it is going to load more settings after base settings are loaded
####

# These dicts are defined solely for BACKWARDS COMPATIBILITY with existing plugins which may theoretically
# rely upon them. Please do not add new references to these dicts!
# - If you need to access the settings values in this module, use pydantic_settings.
# - If you need to access to these values elsewhere, use the corresponding rendered `settings.*`
#   value rathering than diving into these dicts.
ENV_TOKENS = _pydantic_settings_dict
AUTH_TOKENS = _pydantic_settings_dict
ENV_FEATURES = pydantic_settings.FEATURES
ENV_CELERY_QUEUES = pydantic_settings.CELERY_QUEUES
ALTERNATE_QUEUE_ENVS = _pydantic_alternate_worker_queues

# Load production.py in plugins
add_plugins(__name__, ProjectType.CMS, SettingsType.PRODUCTION)


#######################################################################################################################
#### MORE SETTINGS POST-PROCESSING
####
#### More post-processing, but these will not be available Django plugins.
#### Unclear whether or not these are down here intentionally.
####

############# CORS headers for cross-domain requests #################
if FEATURES["ENABLE_CORS_HEADERS"]:
    CORS_ALLOW_CREDENTIALS = True
    if hasattr(pydantic_settings, "CORS_ORIGIN_WHITELIST"):
        CORS_ORIGIN_WHITELIST = pydantic_settings.CORS_ORIGIN_WHITELIST
    if hasattr(pydantic_settings, "CORS_ORIGIN_ALLOW_ALL"):
        CORS_ORIGIN_ALLOW_ALL = pydantic_settings.CORS_ORIGIN_ALLOW_ALL
    if hasattr(pydantic_settings, "CORS_ALLOW_INSECURE"):
        CORS_ALLOW_INSECURE = pydantic_settings.CORS_ALLOW_INSECURE

######################## CELERY ROTUING ########################

# Defines alternate environment tasks, as a dict of form { task_name: alternate_queue }
ALTERNATE_ENV_TASKS = {
    "completion_aggregator.tasks.update_aggregators": "lms",
    "openedx.core.djangoapps.content.block_structure.tasks.update_course_in_cache": "lms",
    "openedx.core.djangoapps.content.block_structure.tasks.update_course_in_cache_v2": "lms",
}

# Defines the task -> alternate worker queue to be used when routing.
EXPLICIT_QUEUES = {
    "lms.djangoapps.grades.tasks.compute_all_grades_for_course": {
        "queue": POLICY_CHANGE_GRADES_ROUTING_KEY
    },
    "lms.djangoapps.grades.tasks.recalculate_course_and_subsection_grades_for_user": {
        "queue": SINGLE_LEARNER_COURSE_REGRADE_ROUTING_KEY
    },
    "cms.djangoapps.contentstore.tasks.update_search_index": {
        "queue": UPDATE_SEARCH_INDEX_JOB_QUEUE
    },
}

############## XBlock extra mixins ############################
XBLOCK_MIXINS += tuple(XBLOCK_EXTRA_MIXINS)

# Translation overrides
if pydantic_settings.LANGUAGE_COOKIE:
    LANGUAGE_COOKIE_NAME = pydantic_settings.LANGUAGE_COOKIE

############## DRF overrides ##############
REST_FRAMEWORK.update(pydantic_settings.REST_FRAMEWORK)

# keys for  big blue button live provider
# TODO: This should not be in the core platform. If it has to stay for now, though, then we should move these
#       defaults into common.py
COURSE_LIVE_GLOBAL_CREDENTIALS["BIG_BLUE_BUTTON"] = {
    "KEY": pydantic_settings.BIG_BLUE_BUTTON_GLOBAL_KEY,
    "SECRET": pydantic_settings.BIG_BLUE_BUTTON_GLOBAL_SECRET,
    "URL": pydantic_settings.BIG_BLUE_BUTTON_GLOBAL_URL,
}

# TODO: We believe that this could be more simply defined as CMS_ROOT_URL. We are not making the change now,
#       but please don't follow this pattern in other defaults...
INACTIVE_USER_URL = f"http{'s' if HTTPS == 'on' else ''}://{CMS_BASE}"

############## Event bus producer ##############
EVENT_BUS_PRODUCER_CONFIG = merge_producer_configs(
    EVENT_BUS_PRODUCER_CONFIG, pydantic_settings.EVENT_BUS_PRODUCER_CONFIG
)

############## Authoring API drf-spectacular openapi settings ##############
# These fields override the spectacular settings default values.
# Any fields not included here will use the default values.
SPECTACULAR_SETTINGS = {
    "TITLE": "Authoring API",
    "DESCRIPTION": f"""Experimental API to edit xblocks and course content.
    \n\nDanger: Do not use on running courses!
    \n\n - How to gain access: Please email the owners of this openedx service.
    \n - How to use: This API uses oauth2 authentication with the
    access token endpoint: `{LMS_ROOT_URL}/oauth2/access_token`.
    Please see separately provided documentation.
    \n - How to test: You must be logged in as course author for whatever course you want to test with.
    You can use the [Swagger UI](https://{CMS_BASE}/authoring-api/ui/) to "Try out" the API with your test course. To do this, you must select the "Local" server.
    \n - Public vs. Local servers: The "Public" server is where you can reach the API externally. The "Local" server is
    for development with a local edx-platform version,  and for use via the [Swagger UI](https://{CMS_BASE}/authoring-api/ui/).
    \n - Swaggerfile: [Download link](https://{CMS_BASE}/authoring-api/schema/)""",
    "VERSION": "0.1.0",
    "SERVE_INCLUDE_SCHEMA": False,
    # restrict spectacular to CMS API endpoints (cms/lib/spectacular.py):
    "PREPROCESSING_HOOKS": ["cms.lib.spectacular.cms_api_filter"],
    # remove the default schema path prefix to replace it with server-specific base paths:
    "SCHEMA_PATH_PREFIX": "/api/contentstore",
    "SCHEMA_PATH_PREFIX_TRIM": "/api/contentstore",
    "SERVERS": [
        {"url": AUTHORING_API_URL, "description": "Public"},
        {"url": f"https://{CMS_BASE}/api/contentstore", "description": "Local"},
    ],
}


#######################################################################################################################
# HEY! Don't add anything to the end of this file.
# Add your defaults to common.py instead!
# If you really need to add post-YAML logic, add it above the "DERIVE ANY DERIVED SETTINGS" section.
#######################################################################################################################
